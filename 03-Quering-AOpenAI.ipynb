{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Queries with and without Azure OpenAI"
      ],
      "metadata": {},
      "id": "d59d527f-1100-45ff-b051-5f7c9029d94d"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now that we have our Search Engine loaded **from two different data sources in two diferent indexes**, we are going to try some example queries and then use Azure OpenAI service to see if we can get even better results.\n",
        "\n",
        "The idea is that a user can ask a question about Computer Science (first datasource/index) or about Covid (second datasource/index), and the engine will respond accordingly.\n",
        "This **Multi-Index** demo, mimics the scenario where a company loads multiple type of documents of different types and about completly different topics and the search engine must respond with the most relevant results."
      ],
      "metadata": {},
      "id": "eb9a9444-dc90-4fc3-aea7-8ee918301aba"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Set up variables"
      ],
      "metadata": {},
      "id": "71f6c7e3-9037-4b1e-ae17-1deaa27b9c08"
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import urllib\n",
        "import requests\n",
        "import random\n",
        "from collections import OrderedDict\n",
        "from IPython.display import display, HTML\n",
        "from langchain.llms import AzureOpenAI\n",
        "from langchain.chat_models import AzureChatOpenAI\n",
        "from langchain.vectorstores import FAISS\n",
        "from langchain.docstore.document import Document\n",
        "from langchain.chains.question_answering import load_qa_chain\n",
        "from langchain.chains.qa_with_sources import load_qa_with_sources_chain\n",
        "from langchain.embeddings import HuggingFaceEmbeddings\n",
        "\n",
        "from app.embeddings import OpenAIEmbeddings\n",
        "from app.prompts import STUFF_PROMPT, REFINE_PROMPT, REFINE_QUESTION_PROMPT\n",
        "\n",
        "# Don't mess with this unless you really know what you are doing\n",
        "AZURE_SEARCH_API_VERSION = '2021-04-30-Preview'\n",
        "AZURE_OPENAI_API_VERSION = \"2023-03-15-preview\"\n",
        "\n",
        "# Change these below with your own services credentials\n",
        "# AZURE_SEARCH_ENDPOINT = \"Enter your Azure Cognitive Search Endpoint ...\"\n",
        "# AZURE_SEARCH_KEY = \"Enter your Azure Cognitive Search Primary Key ...\"\n",
        "# AZURE_OPENAI_ENDPOINT = \"Enter your Azure OpenAI Endpoint ...\"\n",
        "# AZURE_OPENAI_KEY = \"Enter your Azure OpenAI Key ...\"\n",
        "AZURE_SEARCH_ENDPOINT = \"https://azure-cog-search-gtekhenxlqzvu.search.windows.net\"\n",
        "AZURE_SEARCH_KEY = \"EPpDuVjPveOV8hhzKu7e17H0AB7QIzrWGqumQK87uEAzSeB9FqUZ\"\n",
        "AZURE_OPENAI_ENDPOINT = \"https://oai-2023-mondelez-chatgpt-01.openai.azure.com/\"\n",
        "AZURE_OPENAI_KEY = \"f86736ea92444e9f836b69de0512ca55\""
      ],
      "outputs": [],
      "execution_count": 1,
      "metadata": {
        "gather": {
          "logged": 1683222806294
        }
      },
      "id": "8e50b404-a061-49e7-a3c7-c6eabc98ff0f"
    },
    {
      "cell_type": "code",
      "source": [
        "# Setup the Payloads header\n",
        "headers = {'Content-Type': 'application/json','api-key': AZURE_SEARCH_KEY}"
      ],
      "outputs": [],
      "execution_count": 2,
      "metadata": {
        "gather": {
          "logged": 1683222806508
        }
      },
      "id": "2f2c22f8-79ab-405c-95e8-77a1978e53bc"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Multi-Index Search queries"
      ],
      "metadata": {},
      "id": "9297d29b-1f61-4dce-858e-bf4272172dba"
    },
    {
      "cell_type": "code",
      "source": [
        "# Index that we are going to query (from Notebook 01 and 02)\n",
        "index1_name = \"cogsrch-index-files\"\n",
        "index2_name = \"cogsrch-index-csv\"\n",
        "indexes = [index1_name, index2_name]"
      ],
      "outputs": [],
      "execution_count": 3,
      "metadata": {
        "scrolled": true,
        "tags": [],
        "gather": {
          "logged": 1683222806736
        }
      },
      "id": "5a46e2d3-298a-4708-83de-9e108b1a117a"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Try questions that you think might be answered or addressed in computer science papers in 2020-2021 or that can be addressed by medical publications about COVID in 2020. Try comparing the results with the open version of ChatGPT.<br>\n",
        "The idea is that the answers using Azure OpenAI only looks at the information contained on these publications.\n",
        "\n",
        "**Example Questions you can ask**:\n",
        "- What is CLP?\n",
        "- How Markov chains work?\n",
        "- What are some examples of reinforcement learning?\n",
        "- What are the main risk factors for Covid-19?\n",
        "- What medicine reduces inflamation in the lungs?\n",
        "- Why Covid doesn't affect kids that much compared to adults?\n",
        "- Does chloroquine really works against covid?\n",
        "- tell me Use cases where I can use deep learning to solve it"
      ],
      "metadata": {},
      "id": "1c62ebb2-d7be-4bfb-b1ba-4db86c11839a"
    },
    {
      "cell_type": "code",
      "source": [
        "# QUESTION = \"What is CLP?\" \n",
        "QUESTION = \"how to install a generator?\" \n",
        "\n",
        "# This questions is interesting since CLP means something in Computer science and means something different in medical field "
      ],
      "outputs": [],
      "execution_count": 4,
      "metadata": {
        "gather": {
          "logged": 1683222806963
        }
      },
      "id": "b9b53c14-19bd-451f-aa43-7ad27ccfeead"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Search on both indexes individually and aggragate results\n",
        "\n",
        "Note: In order to standarize the indexes we are setting 4 mandatory fields to be present on each index: id, title, content, pages, language. These fields must be present in each index so that each document can be treated the same along the code."
      ],
      "metadata": {},
      "id": "f6d925eb-7f9c-429e-a62a-4c37d7702caf"
    },
    {
      "cell_type": "code",
      "source": [
        "agg_search_results = []\n",
        "\n",
        "for index in indexes:\n",
        "    url = AZURE_SEARCH_ENDPOINT + '/indexes/'+ index + '/docs'\n",
        "    url += '?api-version={}'.format(AZURE_SEARCH_API_VERSION)\n",
        "    url += '&search={}'.format(QUESTION)\n",
        "    url += '&select=*'\n",
        "    url += '&$top=10'  # You can change this to anything you need/want\n",
        "    url += '&queryLanguage=en-us'\n",
        "    url += '&queryType=semantic'\n",
        "    url += '&semanticConfiguration=my-semantic-config'\n",
        "    url += '&$count=true'\n",
        "    url += '&speller=lexicon'\n",
        "    url += '&answers=extractive|count-3'\n",
        "    url += '&captions=extractive|highlight-false'\n",
        "\n",
        "    resp = requests.get(url, headers=headers)\n",
        "    print(url)\n",
        "    print(resp.status_code)\n",
        "\n",
        "    search_results = resp.json()\n",
        "    agg_search_results.append(search_results)\n",
        "    print(\"Results Found: {}, Results Returned: {}\".format(search_results['@odata.count'], len(search_results['value'])))"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "https://azure-cog-search-gtekhenxlqzvu.search.windows.net/indexes/cogsrch-index-files/docs?api-version=2021-04-30-Preview&search=how to install a generator?&select=*&$top=10&queryLanguage=en-us&queryType=semantic&semanticConfiguration=my-semantic-config&$count=true&speller=lexicon&answers=extractive|count-3&captions=extractive|highlight-false\n200\nResults Found: 321, Results Returned: 10\nhttps://azure-cog-search-gtekhenxlqzvu.search.windows.net/indexes/cogsrch-index-csv/docs?api-version=2021-04-30-Preview&search=how to install a generator?&select=*&$top=10&queryLanguage=en-us&queryType=semantic&semanticConfiguration=my-semantic-config&$count=true&speller=lexicon&answers=extractive|count-3&captions=extractive|highlight-false\n200\nResults Found: 40376, Results Returned: 10\n"
        }
      ],
      "execution_count": 5,
      "metadata": {
        "gather": {
          "logged": 1683222808171
        }
      },
      "id": "faf2e30f-e71f-4533-ab52-27d048b80a89"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Display the top results (from both searches) based on the score"
      ],
      "metadata": {
        "tags": []
      },
      "id": "b7fd0fe5-4ee0-42e2-a920-72b93a407389"
    },
    {
      "cell_type": "code",
      "source": [
        "display(HTML('<h4>Top Answers</h4>'))\n",
        "\n",
        "for search_results in agg_search_results:\n",
        "    for result in search_results['@search.answers']:\n",
        "        if result['score'] > 0.5: # Show answers that are at least 50% of the max possible score=1\n",
        "            display(HTML('<h5>' + 'Answer - score: ' + str(result['score']) + '</h5>'))\n",
        "            display(HTML(result['text']))\n",
        "            \n",
        "print(\"\\n\\n\")\n",
        "display(HTML('<h4>Top Results</h4>'))\n",
        "\n",
        "file_content = OrderedDict()\n",
        "\n",
        "for search_results in agg_search_results:\n",
        "    for result in search_results['value']:\n",
        "        if result['@search.rerankerScore'] > 1: # Show results that are at least 25% of the max possible score=4\n",
        "            display(HTML('<h5>' + str(result['title']) + '&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;score: '+ str(result['@search.rerankerScore']) + '</h5>'))\n",
        "            display(HTML(result['@search.captions'][0]['text']))\n",
        "            file_content[result['id']]={\n",
        "                                    \"title\": result['title'],\n",
        "                                    \"chunks\": result['pages'],\n",
        "                                    \"language\": result['language'], \n",
        "                                    \"caption\": result['@search.captions'][0]['text'],\n",
        "                                    \"score\": result['@search.rerankerScore'],\n",
        "                                    \"location\": result['metadata_storage_path']                  \n",
        "                                }"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "<h4>Top Answers</h4>"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "\n\n\n"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "<h4>Top Results</h4>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "<h5>wc_br0163131en_005.book&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;score: 1.3916397094726562</h5>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "NEVER install a generator in an enclosed area such as a tunnel or a trench. Using a generator in a tunnel or a trench CAN KILL YOU IN MINUTES. Generator exhaust contains carbon monoxide. This is a poison you cannot see or smell. NEVER use this generator inside a tunnel or a trench."
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "<h5>None&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;score: 1.2873306274414062</h5>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "Installation of such a system includes the following: • Selecting a Location • Grounding the generator. • Providing a fuel supply. • Mounting the load center. • Connecting power source and load lines. • Connecting system control wiring. • Post installation tests and adjustments."
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "<h5>untitled&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;score: 1.2366943359375</h5>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "The generator set should be set up by a certified electrician.  1.1.8 NEVER operate generator in standing water. 1.1.9 NEVER touch the hot engine, exhaust, or generator components. Burns will result. 1.1.10 NEVER start a machine in need of repair. 1.1.11 Use the emergency stop button only in an actual emergency."
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "<h5>R650 GENERATOR SERVICE MANUAL&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;score: 1.1716384887695312</h5>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "Be careful not  to  put gasoline, matches,  gunpowder, oil cloth,  straw,  trash  and  any  other  inflammables  near the generator.   0 Operate the generator at least 1 meter (4 feet) away from  a building or wall. 3. Do not operate  the  generator in a  room,  cave or  tunnel. Always  operate in a well-ventilated area."
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "<h5>Microsoft Word - Genset Service Manual_0961-0518_X3.3_21.12.07.doc&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;score: 1.1224365234375</h5>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "• Make sure generator set is mounted in a   manner to prevent combustible materials  from accumulating under or near the unit. • Remove all unnecessary grease and oil from  the unit. Accumulated grease and oil can  cause over-heating and engine damage  which present a potential fire hazard."
          },
          "metadata": {}
        }
      ],
      "execution_count": 6,
      "metadata": {
        "gather": {
          "logged": 1683222808759
        }
      },
      "id": "9e938337-602d-4b61-8141-b8c92a5d91da"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Comments on Query results"
      ],
      "metadata": {},
      "id": "52a6d3e6-afb2-4fa7-96d3-69bc2373ded5"
    },
    {
      "cell_type": "markdown",
      "source": [
        "As seen above the semantic search feature of Azure Cognitive Search service is good. It gives us some answers and also the top results with the corresponding file and the paragraph where the answers is possible located.\n",
        "\n",
        "Let's see if we can make this better with Azure OpenAI"
      ],
      "metadata": {},
      "id": "84e02227-6a92-4944-86f8-6c1e38d90fe4"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Using Azure OpenAI\n",
        "\n",
        "Of course we want OpenAI to give a better answer, so we instead of sending these results, we send the content of the documents of the search result articles to OpenAI and lets GPT model give the answer.\n",
        "\n",
        "The problem is that the content of the search result files is or can be very lengthy, more than the allowed tokens allowed by the GPT Azure OpenAI models. So what we need to do is to split in chunks, vectorize and do a vector semantic search. \n",
        "\n",
        "Notice that **the documents chunks are already done in Azure Search**. file_content dictionary (created in the cell above) contains the pages (chunks) of each document. So we dont really need to chunk them again, each doc page for sure will fit on the max tokens limit of the completions LLM and of the embedding LLM.\n",
        "\n",
        "We will use a genius library call LangChain that wraps a lot of boiler plate code."
      ],
      "metadata": {},
      "id": "8df3e6d4-9a09-4b0f-b328-238738ccfaec"
    },
    {
      "cell_type": "code",
      "source": [
        "# Set the ENV variables that Langchain needs to connect to Azure OpenAI\n",
        "os.environ[\"OPENAI_API_BASE\"] = os.environ[\"AZURE_OPENAI_ENDPOINT\"] = AZURE_OPENAI_ENDPOINT\n",
        "os.environ[\"OPENAI_API_KEY\"] = os.environ[\"AZURE_OPENAI_API_KEY\"] = AZURE_OPENAI_KEY\n",
        "os.environ[\"OPENAI_API_VERSION\"] = os.environ[\"AZURE_OPENAI_API_VERSION\"] = AZURE_OPENAI_API_VERSION"
      ],
      "outputs": [],
      "execution_count": 7,
      "metadata": {
        "gather": {
          "logged": 1683222809014
        }
      },
      "id": "eea62a7d-7e0e-4a93-a89c-20c96560c665"
    },
    {
      "cell_type": "code",
      "source": [
        "docs = []\n",
        "for key,value in file_content.items():\n",
        "    for page in value[\"chunks\"]:\n",
        "        docs.append(Document(page_content=page, metadata={\"source\": value[\"location\"]}))\n",
        "        \n",
        "print(\"Number of chunks:\",len(docs))"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Number of chunks: 168\n"
        }
      ],
      "execution_count": 8,
      "metadata": {
        "gather": {
          "logged": 1683222809222
        }
      },
      "id": "8f7b41d2-65b0-4058-8a46-c76cf6960720"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Depending of the amount of chunks/pages returned from the search result, which is very related to the size of the documents returned\n",
        "we pick the embedding model that give us fast results. <br>The logic is, if there is less than 50 chunks (of 5000 chars each) to vectorize then we use \n",
        "OpenAI models which currently don't offer batch processing, but if there is more than 50 chunks we use a BERT based in-memory model that processes in batches and in parallel (it is recommended a VM of at least 4 cores).\n",
        "\n",
        "For more information on in-memory models that you can use, see [HERE](https://www.sbert.net/docs/pretrained_models.html)"
      ],
      "metadata": {},
      "id": "c5403dee-a4c4-420c-9819-68151d973695"
    },
    {
      "cell_type": "code",
      "source": [
        "# Select the Embedder model\n",
        "if len(docs) < 50:\n",
        "    # OpenAI models are accurate but slower\n",
        "    embedder = OpenAIEmbeddings(document_model_name=\"text-embedding-ada-002\", query_model_name=\"text-embedding-ada-002\") \n",
        "else:\n",
        "    # Bert based models are faster (3x-10x) but not as great in accuracy as OpenAI models\n",
        "    # Since this repo supports Multiple languages we need to use a multilingual model. \n",
        "    # But if English only is the requirement, use \"multi-qa-MiniLM-L6-cos-v1\"\n",
        "    # The fastest english model is \"all-MiniLM-L12-v2\"\n",
        "    if random.choice(list(file_content.items()))[1][\"language\"] == \"en\":\n",
        "        embedder = HuggingFaceEmbeddings(model_name = 'multi-qa-MiniLM-L6-cos-v1')\n",
        "    else:\n",
        "        embedder = HuggingFaceEmbeddings(model_name = 'distiluse-base-multilingual-cased-v2')"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "/anaconda/envs/envMark22/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n  from .autonotebook import tqdm as notebook_tqdm\nDownloading (…)5fedf/.gitattributes: 100%|██████████| 737/737 [00:00<00:00, 3.72MB/s]\nDownloading (…)_Pooling/config.json: 100%|██████████| 190/190 [00:00<00:00, 828kB/s]\nDownloading (…)2cb455fedf/README.md: 100%|██████████| 11.5k/11.5k [00:00<00:00, 35.0MB/s]\nDownloading (…)b455fedf/config.json: 100%|██████████| 612/612 [00:00<00:00, 2.52MB/s]\nDownloading (…)ce_transformers.json: 100%|██████████| 116/116 [00:00<00:00, 568kB/s]\nDownloading (…)edf/data_config.json: 100%|██████████| 25.5k/25.5k [00:00<00:00, 68.4MB/s]\nDownloading pytorch_model.bin: 100%|██████████| 90.9M/90.9M [00:00<00:00, 205MB/s]\nDownloading (…)nce_bert_config.json: 100%|██████████| 53.0/53.0 [00:00<00:00, 228kB/s]\nDownloading (…)cial_tokens_map.json: 100%|██████████| 112/112 [00:00<00:00, 566kB/s]\nDownloading (…)5fedf/tokenizer.json: 100%|██████████| 466k/466k [00:00<00:00, 123MB/s]\nDownloading (…)okenizer_config.json: 100%|██████████| 383/383 [00:00<00:00, 1.07MB/s]\nDownloading (…)fedf/train_script.py: 100%|██████████| 13.8k/13.8k [00:00<00:00, 45.1MB/s]\nDownloading (…)2cb455fedf/vocab.txt: 100%|██████████| 232k/232k [00:00<00:00, 272MB/s]\nDownloading (…)455fedf/modules.json: 100%|██████████| 349/349 [00:00<00:00, 1.29MB/s]\n"
        }
      ],
      "execution_count": 9,
      "metadata": {
        "gather": {
          "logged": 1683222817063
        }
      },
      "id": "a03f1f10-32b0-4c1e-8a0e-eee1b1d29ce7"
    },
    {
      "cell_type": "code",
      "source": [
        "embedder"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 10,
          "data": {
            "text/plain": "HuggingFaceEmbeddings(client=SentenceTransformer(\n  (0): Transformer({'max_seq_length': 512, 'do_lower_case': False}) with Transformer model: BertModel \n  (1): Pooling({'word_embedding_dimension': 384, 'pooling_mode_cls_token': False, 'pooling_mode_mean_tokens': True, 'pooling_mode_max_tokens': False, 'pooling_mode_mean_sqrt_len_tokens': False})\n  (2): Normalize()\n), model_name='multi-qa-MiniLM-L6-cos-v1', cache_folder=None, model_kwargs={})"
          },
          "metadata": {}
        }
      ],
      "execution_count": 10,
      "metadata": {
        "gather": {
          "logged": 1683222817293
        }
      },
      "id": "a5cc7ae5-6fe9-4fd8-992d-0507297387ea"
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "if(len(docs)>1):\n",
        "    db = FAISS.from_documents(docs, embedder)\n",
        "else:\n",
        "    print(\"No results Found\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "CPU times: user 36.4 s, sys: 29.9 s, total: 1min 6s\nWall time: 1min 22s\n"
        }
      ],
      "execution_count": 11,
      "metadata": {},
      "id": "3315033a-4a08-4db5-8f5c-fa0a99892dc4"
    },
    {
      "cell_type": "code",
      "source": [
        "docs_db = db.similarity_search(QUESTION, k=4)"
      ],
      "outputs": [],
      "execution_count": 12,
      "metadata": {
        "gather": {
          "logged": 1683222901176
        }
      },
      "id": "57429335-34d3-458a-b7c9-52482a0936d5"
    },
    {
      "cell_type": "markdown",
      "source": [
        "At this point we already have the most similar chunks (in order of relevance given by the in-memory vector cosine similarity search) in docs_db"
      ],
      "metadata": {},
      "id": "17247488-7d14-4178-9add-31eb1afcbcbe"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Now we use GPT-3.5(Turbo) using map-reduce chain in order to stay within the limits of the allow model's token count\n",
        "\n",
        "for more information on the different types of prompts for these chains please see here:\n",
        "\n",
        "https://github.com/hwchase17/langchain/tree/master/langchain/chains/question_answering"
      ],
      "metadata": {},
      "id": "793c4788-715e-44dd-b2b8-3f1c3201e4e0"
    },
    {
      "cell_type": "code",
      "source": [
        "# Make sure you have the deployment named \"gpt-35-turbo\" for the model \"gpt-35-turbo (0301)\". \n",
        "# Use \"gpt-4\" if you have it available.\n",
        "llm = AzureChatOpenAI(deployment_name=\"gpt-35-turbo\", temperature=0.9, max_tokens=500)\n",
        "chain = load_qa_with_sources_chain(llm, chain_type=\"map_reduce\", return_intermediate_steps=True)"
      ],
      "outputs": [],
      "execution_count": 13,
      "metadata": {
        "gather": {
          "logged": 1683222901504
        }
      },
      "id": "634f5bd8-0d56-47b8-84fd-fe9b678bfc32"
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "response = chain({\"input_documents\": docs_db, \"question\": QUESTION}, return_only_outputs=True)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "CPU times: user 744 ms, sys: 637 ms, total: 1.38 s\nWall time: 37.1 s\n"
        }
      ],
      "execution_count": 14,
      "metadata": {},
      "id": "a1e619b8-1dcf-431b-8aad-f1696a09c2ac"
    },
    {
      "cell_type": "code",
      "source": [
        "answer = response['output_text']\n",
        "\n",
        "display(HTML('<h4>Azure OpenAI ChatGPT Answer:</h4>'))\n",
        "print(answer.split(\"SOURCES:\")[0])\n",
        "#20230419 Mark Vogt (Avanade) ADDED exception-handling in case \"answer\" comes back with NO \"SOURCES:\"...\n",
        "if(answer.find(\"SOURCES:\") < 0):\n",
        "    print(\"Sources: none\")\n",
        "else: \n",
        "    print(\"Sources:\")\n",
        "    print(answer.split(\"SOURCES:\")[1].replace(\" \",\"\").split(\",\"))"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "<h4>Azure OpenAI ChatGPT Answer:</h4>"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "To install a generator, steps must be taken to drain the fuel tank, change the engine oil, pour clean engine oil into the cylinder, and secure the generator (source 1). It should be positioned on firm, level ground, away from areas where people may be present, and never used indoors (source 2). It should be secured to the engine and frame, and connections to a building's electrical system should be made by a qualified electrician and comply with all applicable laws and electrical codes (source 4).\nSources: none\n"
        }
      ],
      "execution_count": 15,
      "metadata": {
        "gather": {
          "logged": 1683222938574
        }
      },
      "id": "8cddb1cb-a4a0-4e2f-9f0c-4216b0f232b2"
    },
    {
      "cell_type": "code",
      "source": [
        "response"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 16,
          "data": {
            "text/plain": "{'intermediate_steps': ['3.9.2 Disconnect the fuel line from the carburetor. Place the open end of the\\nfuel line into a suitable container and open the fuel valve to drain the\\nfuel from the tank. \\n\\nGasoline is extremely flammable. Drain the fuel tank in a well-\\nventilated area. DO NOT drain the fuel tank in an area with flames or\\nsparks.\\n\\n3.9.3 Loosen the drain screw on the carburetor and drain any remaining fuel\\nfrom the carburetor.\\n\\n3.9.4 Change the engine oil.\\n\\n3.9.5 Remove the spark plug and pour approximately 30 ml (1 ounce) of\\nclean engine oil into the cylinder. Crank the engine a few turns to\\ndistribute the oil to the inside of the cylinder walls.\\n\\n3.9.6 Pull the starter rope slowly until resistance is felt and leave the handle\\nin this position. This ensures that the intake and exhaust valves are\\nclosed.\\n\\n3.9.7 Store the generator in a clean, dry area.\\n\\n3.10.1 Turn the engine fuel valve to the OFF position.\\n\\n3.10.2 Position the generator level to prevent fuel from spilling.\\n\\n3.10.3 Secure the generator by tying it down with a suitable rope. \\n\\nWhen installing a generator, steps must be taken to drain the fuel tank, change the engine oil, pour clean engine oil into the cylinder, and secure the generator. The fuel valve must be turned off, and the generator must be tied down to prevent fuel from spilling.',\n  '2.4 Installation\\nPlace the generator in an area where it will not be exposed to rain, snow, or direct sunlight. Make sure it is positioned on firm, level ground, so it will not slide or shift. Position the engine exhaust away from areas where people may be present.\\nUsing a generator indoors CAN KILL YOU IN MINUTES. Generator exhaust contains carbon monoxide. This is a poison you cannot see or smell. NEVER use this generator inside a home or garage, EVEN IF doors and windows are open. Only use this generator OUTSIDE and far away from windows, doors, and vents.\\nNEVER install a generator in an enclosed area such as a tunnel or a trench. Using a generator in a tunnel or a trench CAN KILL YOU IN MINUTES. Generator exhaust contains carbon monoxide. This is a poison you cannot see or smell. NEVER use this generator inside a tunnel or a trench.',\n  'Installation:\\n9.7.8 Position the generator into the frame.\\n9.7.9 Using Loctite 231 or equivalent on the screws (d), secure the generator to the engine. Torque the screws to 69Nm (50 ft.lbs.).\\n9.7.10 Using Loctite 231 or equivalent on screws (c), secure the flex plates to the engine. Torque the screws to 45 Nm (33 ft.lbs.); 35Nm (25 ft.lbs.)\\non G 25 models.\\n9.7.11 Using screws (b), secure the shock mounts to the frame.\\n9.7.12 Secure the screens (a) to both sides of the generator housing.\\n9.7.13 Reconnect all wiring.\\n9.7.14 Reinstall the control panel enclosure and the roof.',\n  'The generator set should be set up by a certified electrician. Additionally, connections to a building’s electrical system must be made by a qualified electrician and comply with all applicable laws and electrical codes.'],\n 'output_text': \"To install a generator, steps must be taken to drain the fuel tank, change the engine oil, pour clean engine oil into the cylinder, and secure the generator (source 1). It should be positioned on firm, level ground, away from areas where people may be present, and never used indoors (source 2). It should be secured to the engine and frame, and connections to a building's electrical system should be made by a qualified electrician and comply with all applicable laws and electrical codes (source 4).\"}"
          },
          "metadata": {}
        }
      ],
      "execution_count": 16,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1683222938804
        }
      },
      "id": "105c1733-e5b5-4eca-9562-2dafdb60c2b8"
    },
    {
      "cell_type": "code",
      "source": [
        "answer"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 17,
          "data": {
            "text/plain": "\"To install a generator, steps must be taken to drain the fuel tank, change the engine oil, pour clean engine oil into the cylinder, and secure the generator (source 1). It should be positioned on firm, level ground, away from areas where people may be present, and never used indoors (source 2). It should be secured to the engine and frame, and connections to a building's electrical system should be made by a qualified electrician and comply with all applicable laws and electrical codes (source 4).\""
          },
          "metadata": {}
        }
      ],
      "execution_count": 17,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1683222939280
        }
      },
      "id": "957643d6-6f90-477c-a774-8720e3340d1c"
    },
    {
      "cell_type": "code",
      "source": [
        "# Uncomment if you want to inspect the results from each top similar chunk (k=4 by default)\n",
        "response['intermediate_steps']"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 18,
          "data": {
            "text/plain": "['3.9.2 Disconnect the fuel line from the carburetor. Place the open end of the\\nfuel line into a suitable container and open the fuel valve to drain the\\nfuel from the tank. \\n\\nGasoline is extremely flammable. Drain the fuel tank in a well-\\nventilated area. DO NOT drain the fuel tank in an area with flames or\\nsparks.\\n\\n3.9.3 Loosen the drain screw on the carburetor and drain any remaining fuel\\nfrom the carburetor.\\n\\n3.9.4 Change the engine oil.\\n\\n3.9.5 Remove the spark plug and pour approximately 30 ml (1 ounce) of\\nclean engine oil into the cylinder. Crank the engine a few turns to\\ndistribute the oil to the inside of the cylinder walls.\\n\\n3.9.6 Pull the starter rope slowly until resistance is felt and leave the handle\\nin this position. This ensures that the intake and exhaust valves are\\nclosed.\\n\\n3.9.7 Store the generator in a clean, dry area.\\n\\n3.10.1 Turn the engine fuel valve to the OFF position.\\n\\n3.10.2 Position the generator level to prevent fuel from spilling.\\n\\n3.10.3 Secure the generator by tying it down with a suitable rope. \\n\\nWhen installing a generator, steps must be taken to drain the fuel tank, change the engine oil, pour clean engine oil into the cylinder, and secure the generator. The fuel valve must be turned off, and the generator must be tied down to prevent fuel from spilling.',\n '2.4 Installation\\nPlace the generator in an area where it will not be exposed to rain, snow, or direct sunlight. Make sure it is positioned on firm, level ground, so it will not slide or shift. Position the engine exhaust away from areas where people may be present.\\nUsing a generator indoors CAN KILL YOU IN MINUTES. Generator exhaust contains carbon monoxide. This is a poison you cannot see or smell. NEVER use this generator inside a home or garage, EVEN IF doors and windows are open. Only use this generator OUTSIDE and far away from windows, doors, and vents.\\nNEVER install a generator in an enclosed area such as a tunnel or a trench. Using a generator in a tunnel or a trench CAN KILL YOU IN MINUTES. Generator exhaust contains carbon monoxide. This is a poison you cannot see or smell. NEVER use this generator inside a tunnel or a trench.',\n 'Installation:\\n9.7.8 Position the generator into the frame.\\n9.7.9 Using Loctite 231 or equivalent on the screws (d), secure the generator to the engine. Torque the screws to 69Nm (50 ft.lbs.).\\n9.7.10 Using Loctite 231 or equivalent on screws (c), secure the flex plates to the engine. Torque the screws to 45 Nm (33 ft.lbs.); 35Nm (25 ft.lbs.)\\non G 25 models.\\n9.7.11 Using screws (b), secure the shock mounts to the frame.\\n9.7.12 Secure the screens (a) to both sides of the generator housing.\\n9.7.13 Reconnect all wiring.\\n9.7.14 Reinstall the control panel enclosure and the roof.',\n 'The generator set should be set up by a certified electrician. Additionally, connections to a building’s electrical system must be made by a qualified electrician and comply with all applicable laws and electrical codes.']"
          },
          "metadata": {}
        }
      ],
      "execution_count": 18,
      "metadata": {
        "gather": {
          "logged": 1683222939681
        }
      },
      "id": "11345374-6420-4b36-b061-795d2a804c85"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Summary\n",
        "##### This answer is way better than taking just the result from Azure Cognitive Search. So the summary is:\n",
        "- Azure Cognitive Search give us the top results (context)\n",
        "- Azure OpenAI takes these results and understand the content and uses it as context to give the best answer\n",
        "- Best of two worlds!"
      ],
      "metadata": {},
      "id": "f347373a-a5be-473d-b64e-0f6b6dbcd0e0"
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "envmark22",
      "language": "python",
      "display_name": "(envMark22)"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.3",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "microsoft": {
      "ms_spell_check": {
        "ms_spell_check_language": "en"
      },
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    },
    "kernel_info": {
      "name": "envmark22"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}